{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script src=\"//yihui.org/js/math-code.js\"></script>\n",
    "<!-- Just one possible MathJax CDN below. You may use others. -->\n",
    "<script async\n",
    "  src=\"//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML\">\n",
    "</script>\n",
    "# AUTOGRAD: DIFERENCIAÇÃO AUTOMÁTICA\n",
    "\n",
    "No centro de todas as redes neurais em PyTorch está o pacote `autograd`. Vamos primeiramente introduzir brevemente isto, e então partir para o treinamento da nossa primeira rede neural.\n",
    "\n",
    "O pacote `autograd` fornece a diferenciação automática para todas operações em Tensores. É uma estrutura definida por execução (_define-by-run framework_), que significa que sua retropropagação é definida pela forma como seu código é executado e que toda iteração pode ser diferente.\n",
    "\n",
    "Observemos de forma mais simples através de alguns exemplos.\n",
    "\n",
    "## Tensor\n",
    "\n",
    "`torch.Tensor` é a classe central do pacote. Se configurar seu atributo `.requires_grad` como `True` (verdadeiro), este começa a rastrear todas operações no mesmo. Quando finalizar sua computação, pode chamar `.backward()` e ter todos os gradientes computados automaticamente. O gradiente para este tensor será acumulado no atributo `.grad`.\n",
    "\n",
    "Para parar o rastreamento do histórico de um tensor, podemos chamar `.detach()` para destacá-lo do histórico de computação, e evitar que a computação futura seja rastreada.\n",
    "\n",
    "Para eviter rastreamento do histórico (e o uso da memória), podemos também empacotar o bloc de código em `with torch.no_grad():`. Isso pode ser particularmente de grande ajuda quando for avaliar um modelo, pois o modelo pode conter parâmetros treináveis com `requires_grad=True`, mas para o qual não precisamos dos gradientes.\n",
    "\n",
    "Há mais uma classe muito importante para a implementação do autograd - uma `Function`.\n",
    "\n",
    "`Tensor` e `Function` são interconectados e constroem um gráfico acíclico, que codifica um histórico completo da computação. Cada tensor tem um atributo `.grad_fn` que referencia uma `Function` que criara o `Tensor` (exceto para os Tensores criados pelo usuário - seus `grad_fn` são `None`).\n",
    "\n",
    "Se quisermos computar os derivativos, podemos chamar `.backward()` em um `Tensor`. Se `Tensor` for um escalar (i.e., contém apenas um elemento), não precisamos especificar alrgumento algum ao `backward()`, no entanto, se tiver mais elementos, precisamos especificar um argumento `gradient` que é um tensor de dimensão correspondente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crie um tensor e configure `requires_grad=True` para rastrear a computação com isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça uma operação de tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`y` foi criado como um resultado de uma operação, então possui um `grad_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x7f1379161a10>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça mais operações em `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`requires_grad_(...)` altera uma _flag_ `requires_grad` de um tensor existente de forma _in-place_. O _input_ (entrada) padrão da _flag_ é `False` se não fornecido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x7f13ec431e50>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradientes\n",
    "\n",
    "Vamos fazer a retropropagação agora. Como `out` contém apenas um valor escalar, `out.backward()` equivale a `out.backward(torch.tensor(1.))`.\n",
    "\n",
    "Imprime gradientes _d(out)/dx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado foi uma matriz de `4.5`. Vamos chamar o _Tensor_ `out` de \"$o$\". Temos que $o = \\frac{1}{4}\\sum_i z_i$,\n",
    "$z_i = 3(x_i+2)^2$ e $z_i\\bigr\\rvert_{x_i=1} = 27$.\n",
    "Portanto,\n",
    "$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$, e consequentemente\n",
    "$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$.\n",
    "\n",
    "Matematicamente, se tivermos uma função com valores vetoriais $\\vec{y} = f(\\vec{x})$, então o gradiente de $\\vec{x}$ de $\\vec{y}$ é uma matriz Jacobiana.\n",
    "\n",
    "<!-- $$J = \n",
    "    \\begin{pmatrix}\n",
    "    \\frac{\\partial y_1}{\\partial x_1} & \\cdots & \\frac{\\partial y_1}{\\partial x_n} \\\\\n",
    "    \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\frac{\\partial y_n}{\\partial x_1} & \\cdots & \\frac{\\partial y_n}{\\partial x_n}$$ -->\n",
    "\n",
    "Genericamente falando, `torch.autograd` é um motor para computar o produto do vetor Jacobiano. Isto é, dado um vetor $\\vec{v}=(v_1 \\space v_2 \\cdots v_m)^T$, compute o produto $\\vec{v}^T \\bullet J$. Se $\\vec{v}$ for gradiente de uma função escalar $l=g(\\vec{y})$, i.e., $\\vec{v} = \\left(\\frac{\\partial l}{\\partial y_1} \\cdots \\frac{\\partial l}{\\partial y_m}\\right)$, então pela regra da cadeia, o produto do vetor Jacobiano seria o gradiente de $\\vec{x}$ de $l$.\n",
    "\n",
    "(Note que $\\vec{v}^T \\bullet J$ resulta em um vetor de uma linha, que pode ser tratado como um vetor de uma coluna invertendo a operação para $J^T \\bullet \\vec{v}$.)\n",
    "\n",
    "Esta característica do produto do vetor Jacobiano é bastante conveniente para alimentar gradientes externos em um modelo que tem a _output_ (saída) não-escalar.\n",
    "\n",
    "Para mais detalhes acesse [aqui](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html).\n",
    "\n",
    "Agora, observemos um exemplo de produto do vetor Jacobiano:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-723.9316,  522.3034, -503.7703], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso, `y` não é mais um escalar. `torch.autograd` não pôde computar completamente o Jacobiano de forma direta, mas se quisermos apenas o produto do vetor Jacobiano, simplesmente passamos o vetor como argumento de `backward`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também parar o autograd de rastrar o histórico nos Tensores com `.requires_grad=True`, seja empacotando o bloco de código em `with torch.no_grad():` ou usando `.detach()` para ter um novo Tensor com o mesmo conteúdo, mas que não requer os gradientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empacotamento de bloco de código\n",
      "True\n",
      "True\n",
      "False\n",
      "\n",
      "Novo Tensor com mesmo conteúdo, mas sem histórico de gradientes.\n",
      "True\n",
      "False\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print(\"Empacotamento de bloco de código\")\n",
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)\n",
    "    \n",
    "print(\"\\nNovo Tensor com mesmo conteúdo, mas sem histórico de gradientes.\")\n",
    "print(x.requires_grad)\n",
    "y = x.detach()\n",
    "print(y.requires_grad)\n",
    "print(x.eq(y).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Referência: [AUTOGRAD: AUTOMATIC DIFFERENTIATION](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
